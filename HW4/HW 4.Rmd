---
title: "HW4"
author: 'BBC: Bichay, Bovee, Coeman'
date: "2/16/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Homework 4

# Slide 47

Use the benchmark function from the rbenchmark package to assess if
there is any performance difference between using apply, sapply,
lapply, and a for loop. This will require you to turn your code for
calculating the summary statistics into functions.

```{r}

#create function to produce summary stats (from class)
fnx = function(x){
  numberNA = sum(is.na(x))
  x = x[!is.na(x)]
  n = length(x)
  out = c(n = n, numberNA = numberNA, mean = mean(x), median = median(x), 
          max = max(x), min = min(x), stdev = sd(x))
  return(out)
}

#create functions from the apply, sapply, lapply and for loop statements made in class
polity_apply <- function(pdata){
  df <- apply(pdata, 2, fnx)
  return(df)
}

polity_lapply <- function(pdata){
  df <- do.call(cbind, lapply(pdata, fnx))
  return(df) 
}


polity_sapply <- function(pdata){
  df <- sapply(pdata, fnx)
  return(df)
}

polity_for <- function(pdata){
  df <- data.frame(democ = rep(NA,7),autoc = rep(NA,7), polity2 = rep(NA,7), xconst = rep(NA,7))
  for(i in pdata){
    df[,i] <- fnx(polity[,i])
  }
  return(df)
}


library(rbenchmark)
#set the columns of interest from the polity data, probably a better way to do this
df <- polity[, c("democ", "autoc", "polity2", "xconst")]
vect <- c('democ','autoc','polity2','xconst')

#run a benchmark test on each of the functions
benchmark(
  polity_apply(df),
  polity_lapply(df),
  polity_sapply(df),
  polity_for(vect),
  replications=100,
  columns=c('test','elapsed','replications')
)
```

# Slide 50

Use tapply to calculate the mean, median, and stdev of polity2 and
xconst for every year in the polity dataframe object. 

```{r}
load("/Users/nickbichay/Desktop/ /aPLS 900/Week 4/polity_dataframe.rda")

#### With tapply

f  <-  function(x) c(mean = mean(x, na.rm=TRUE), median=median(x, na.rm=TRUE), sd = sd(x, na.rm=TRUE)) 

bound <- do.call(rbind, sapply(polity[,c('democ','autoc','polity2','xconst')], function(x) tapply(x, polity$year, f)))

stats <- matrix(bound, nrow=length(unique(polity$year)), ncol=12, 
                        dimnames=list( unique(polity$year),
                            c("democ_mean", "autoc_mean", "polity2_mean", "xconst_mean", "democ_median", "autoc_median", "polity2_median", "xconst_median", "democ_sd", "autoc_sd", "polity2_sd", "xconst_sd"))
                        )


#### With dplyr

library(dplyr)
 stats2 <- polity[,c('democ','autoc','polity2','xconst')] %>% group_by(polity$year) %>% summarise_all(funs(mean, median, sd), na.rm=TRUE)
```


## Functions chapter Problems

```{r}
install.packages("pryr")
```

# Function Components
1.What function allows you to tell if an object is a function?
What function allows you to tell if a function is a primitive function?
  is.function tests whether an object is a function.
  is.primitive tests wheter the function is primitive.

2.  This code makes a list of all functions in the base package.
```{r}
objs <- mget(ls("package:base"), inherits = TRUE)
funs <- Filter(is.function, objs)

#first, create a list of the argument lengths

#creating an empty vector
fun_len_vector <- c()

#writing a for loop that will fill in my empty vector
  #the "formals" gives the actual arguments in a function
  #creating a for loop to loop through a vector of the names of the functions and get their formals
  #checking the length of the formals 
  #assign names to the vector: pipe the function name to the i'th element of the names vector
for (i in 1:length(funs)){
 fun_name <- names(funs)[i]
 len <- length(formals(fun_name)) 
 fun_len_vector[i] <-len
 names(fun_len_vector)[i]<- fun_name
}

#check the length of the newly populated list
length(fun_len_vector)


#### Same output as for loop above, alternate specification. It just gives it as a list instead without labels
#sapply version of the for loop
  #take the name and return the length
length_fun <- function(i){
  .len <- length(formals(i))
  return(.len)
}
  #pass sapply the NAMES, return the length of the formals as a vector
test<- sapply(names(funs), length_fun)
is.vector(test)

#find the maximum (for question 2a)
  #maximum value of arguments in the function length vector
max_fun_leng <- max(fun_len_vector) 

  #which of the elements in this vector has a length of 22?

which_is_longest <- which(fun_len_vector == max_fun_leng)
  #find the name of the function in the indicated position from the which above

names(fun_len_vector)[which_is_longest]

#find the # of functions with no arguments (for question 2b)
print(min(fun_len_vector))  #check lowest value of fun_len_vector
no_args <- which(fun_len_vector == 0) #get positions of the 0 argument functions
only_no_args <- fun_len_vector[no_args] #make a vector of the elements (functions) with no arguments
length(only_no_args) #see how many functions have no arguments

#find the primitive functions (for question 2c)

prim_functions <- is.primitive 

```
Use it to answer the following questions:

2a. Which base function has the most arguments?
  scan, it has 22 arguments
  
2b. How many base functions have no arguments? What’s special about those functions?
  226 base functions have no arguments.
  The special thing is that they are primitive.

2c. How could you adapt the code to find all primitive functions?
  I did this above (only_no_args) vector
  
3. What are the three important components of a function?
  Body (code inside the function), Formals (list of arguments which controls how to call the function), Environment (map of location of variables in function)
  
4. When does printing a function not show what environment it was created in?
  When the function was created in the global environment.
  
# Lexical Scoping

1. What does the following code return? Why? What does each of the three c’s mean?

```{r}
c <- 10
c(c = c)
```
   The code returns 10.
   first c: this is a function c()
   second c: new label c
   third c: assign the value for c (defined above) to the parameter/label c
   
2. What are the four principles that govern how R looks for values?

3. What does the following function return? Make a prediction before running the code yourself.
  inner function squares
  second to inner function adds 1 
  third function multiplies that value by 2
  The function returns 202.

```{r}
f <- function(x) {
  f <- function(x) {
    f <- function(x) {
      x ^ 2
    }
    f(x) + 1
  }
  f(x) * 2
}
f(10)
```

# Function Arguments
1. Clarify the following list of odd function calls:
  x:
    is an object that samples with replacement 
    getting a vector of 1 through 10 plus NA
    output 20 values
  y:
    create a uniform distribution with a minimum of 0 and a max of 1
    with 20 values
  cor:
    k is referring to kendall for the method of correlation argument
    p is referring to pairwise for the use argument
  
  
```{r}
?cor
x <- sample(replace = TRUE, 20, x = c(1:10, NA))
y <- runif(min = 0, max = 1, 20)
cor(m = "k", y = y, u = "p", x = x)
```

2. What does this function return? Why? Which principle does it illustrate?
  This function returns 3.
  The reason that it returns 3 is we assigned y a value of 1 and then are adding x, which = 2. 
  If we did not have the y <-1, it would have defaulted to 0.
  The principle which it illustrates is you can assign a value to y locally.
```{r}
f1 <- function(x = {y <- 1; 2}, y = 0) {
  x + y
}
f1()
```

3. What does this function return? Why? Which principle does it illustrate?
  This function returns 100 because x is looking locally first (within the function's local environment).
  We have assigned z a value of 100
  We have told the function x = z
  So, when we ask for x, it gives us 100.
  It illustrates the principle of name masking.
```{r}
f2 <- function(x = z) {
  z <- 100
  x
}
f2()
```
# Special calls

1. Create a list of all the replacement functions found in the base package. Which ones are primitive functions?
  Skipping for now.
  
2. What are valid names for user-created infix functions?

3. Create an infix xor() operator.
```{r}
`%xor%` <- x | y
x <- 2
y <- 5

%xor% c(x,y)
```   

4. Create infix versions of the set functions intersect(), union(), and setdiff().
```{r}
#union will output everything from both but give you the unique elements
`%unionEmily%` <- function(x,y){
  return(unique(c(x,y)))}

x <- c(1,2,3)
y <- c(3,4,5)
x %unionEmily% y

#intersect will output only the things they have in common 

#setdiff says "take everything in the first thing and get rid of the common things from the second thing"
```
5. Create a replacement function that modifies a random location in a vector.
```{r}

#WITHIN THE FUNCTION
#create a vector LOCATION that is all possible locations within the length of the vector x
#constrain the position to be within the vector, randomly choose a position within the vector
#put the value in the random position in the vector x
#return x
`EmilyFunction<-` = function(x, value){
  location <- 1:length(x)
  random_position <- sample(location, 1)
  x[random_position] = value
  return(x)}


#Testing the function
  #defining a vector
  x <- 1:100
  #calling my function with the value of 150 in a random position in x
  EmilyFunction(x) = 150
  
  #looking at x
  x
```
#Return Values

1. How does the chdir parameter of source() compare to in_dir()? Why might you prefer one approach to the other?

2. What function undoes the action of library()? How do you save and restore the values of options() and par()?

3. Write a function that opens a graphics device, runs the supplied code, and closes the graphics device (always, regardless of whether or not the plotting code worked).
  We have not covered graphics yet.

4. We can use on.exit() to implement a simple version of capture.output().
  We have not covered this yet.
  
capture.output2 <- function(code) {
  temp <- tempfile()
  on.exit(file.remove(temp), add = TRUE)

  sink(temp)
  on.exit(sink(), add = TRUE)

  force(code)
  readLines(temp)
}
capture.output2(cat("a", "b", "c", sep = "\n"))
# [1] "a" "b" "c"
Compare capture.output() to capture.output2(). How do the functions differ? What features have I removed to make the key ideas easier to see? How have I rewritten the key ideas to be easier to understand?

## Functional Programming chapter Problems

# Anonymous Functions

1. Given a function, like "mean", match.fun() lets you find a function. Given a function, can you find its name? Why doesn’t that make sense in R?
  Functions in R can be anonymous and have no name. 


2. Use lapply() and an anonymous function to find the coefficient of variation (the standard deviation divided by the mean) for all columns in the mtcars dataset.
  lapply(mtcars, function(x) sd(x)/mean(x))


3. Use integrate() and an anonymous function to find the area under the curve for the following functions. Use Wolfram Alpha to check your answers.

y = x ^ 2 - x, x in [0, 10]
  integrate(function(x) x^2-x, 0, 10)
y = sin(x) + cos(x), x in [-π, π]
  integrate(function(x) sin(x) + cos(x), -pi, pi)
y = exp(x) / x, x in [10, 20] 
  integrate(function(x) exp(x)/x, 10, 20)

4. A good rule of thumb is that an anonymous function should fit on one line and shouldn’t need to use {}. Review your code. Where could you have used an anonymous function instead of a named function? Where should you have used a named function instead of an anonymous function?
  Not sure, none of the above use {}. Maybe I did them wrong?

# Closures

1. Why are functions created by other functions called closures?
  "they enclose the environment of the parent function and can access all its variables"

2. What does the following statistical function do? What would be a better name for it? (The existing name is a bit of a hint.)

bc <- function(lambda) {
  if (lambda == 0) {
    function(x) log(x)
  } else {
    function(x) (x ^ lambda - 1) / lambda
  }
}

  It's a function that returns the log of x if lambda is 0, otherwise it returns (x ^ lambda - 1) / lambda. Google says this is a box cox transformation, so a better name would be box_cox

3. What does approxfun() do? What does it return?
  It approximates the amount of fun the user is having as they work in R.   But actually, it "returns a function performing (linear or constant) interpolation of the given data points. For a given set of x values, this function will return the corresponding interpolated values."
  
4. What does ecdf() do? What does it return?
  Computes an empirical cumulative distribution function

5. Create a function that creates functions that compute the ith central moment of a numeric vector. You can test it by running the following code:

m1 <- moment(1)
m2 <- moment(2)

x <- runif(100)
stopifnot(all.equal(m1(x), 0))
stopifnot(all.equal(m2(x), var(x) * 99 / 100))

  moment <- function(i) {
    function(x) sum((x-mean(x))^i)/length(x)
  }

6. Create a function pick() that takes an index, i, as an argument and returns a function with an argument x that subsets x with i.

lapply(mtcars, pick(5))
should do the same as this
lapply(mtcars, function(x) x[[5]])

  pick <- function(i){
  function(x) x[[i]]
  }

# Lists of Functions

1. Implement a summary function that works like base::summary(), but uses a list of functions. Modify the function so it returns a closure, making it possible to use it as a function factory.

  function_summary <- function(){
    functions_list <- list(
    "Mean" = mean,
    "Median" = median,
    "Min" = min,
    "Max" = max,
    "1st Qu." = function(x) quantile(x, probs = 0.25),
    "3rd Qu" =  function(x) quantile(x, probs = 0.75)
    )
    function(x){
    lapply(x, function(x))
    }
  }


2. Which of the following commands is equivalent to with(x, f(z))?

x$f(x$z).
f(x$z).
x$f(z).
f(z).
It depends.

B: f(x$z)

# Case Study: Numerical Integration

1. Instead of creating individual functions (e.g., midpoint(), trapezoid(), simpson(), etc.), we could store them in a list. If we did that, how would that change the code? Can you create the list of functions from a list of coefficients for the Newton-Cotes formulae?
  
  I am not sure if I fully understand what is supposed to be done here. 
  
  list_functions <- list(
  "midpoint" = midpoint,
  "trapezoid" = trapezoid,
  "simpson" = simpson,
  "boole" = boole,
  "miline" = milne )
  lapply(list_functions, function(x) composite(sin, 0, pi, n = 10, rule = x))

  This doesn't work, but is this what was being asked?
  ruleslist <- list(
    boole = list(coef = c(7, 32, 12, 32, 7)),
    milne = list(coef = c(2, -1, 2), open = TRUE)
  )
  lapply(ruleslist, function(x) do.call(newton_cotes, x))


2. The trade-off between integration rules is that more complex rules are slower to compute, but need fewer pieces. For sin() in the range [0, π], determine the number of pieces needed so that each rule will be equally accurate. Illustrate your results with a graph. How do they change for different functions? sin(1 / x^2) is particularly challenging.
  
  Not sure how to do this one either. 
  



